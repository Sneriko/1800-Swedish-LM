{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitvenvvenve56eb1c324534f00b97e0476d141161c",
   "display_name": "Python 3.7.4 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('../Datasets/SUC/suc3.xml')\n",
    "root = tree.getroot()\n",
    "ents = [\"PRS\", \"ORG\", \"LOC\", \"TME\", \"MSR\", \"WRK\"]\n",
    "sentsList = []\n",
    "\n",
    "for sent in root.iter('sentence'):\n",
    "    tokensList = []\n",
    "    for child in sent:\n",
    "        if child.tag == 'name':\n",
    "            for token in child.iter('w'):\n",
    "                nameDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                tokensList.append(nameDict)\n",
    "        elif child.tag == 'ne' and child.attrib['type'] in ents:\n",
    "            entityTokenList = child.attrib['name'].split(' ')\n",
    "            for token in child.iter('w'):\n",
    "                neDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|')}\n",
    "                if token.text == entityTokenList[0]:\n",
    "                    neDict['ner'] = 'B-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "                    continue\n",
    "                else:\n",
    "                    neDict['ner'] = 'I-' + child.attrib['type']\n",
    "                    tokensList.append(neDict)\n",
    "                    continue\n",
    "        elif child.tag == 'ne':\n",
    "            for token in child.iter('w'):\n",
    "                tokenDict = {'orth': token.text, 'tag': token.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "                tokensList.append(tokenDict)\n",
    "        elif child.tag == 'w':\n",
    "            tokenDict = {'orth': child.text, 'tag': child.attrib['msd'].replace('.', '|'), \"ner\": \"O\"}\n",
    "            tokensList.append(tokenDict)\n",
    "        else:\n",
    "            continue\n",
    "    sentsList.append(tokensList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sentsList, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datasets/SUC/SUC3IOB2Train.txt', 'w', encoding='utf-8') as trainFile, open('../Datasets/SUC/SUC3IOB2Test.txt', 'w', encoding='utf-8') as testFile:\n",
    "    \n",
    "    for sent in train:\n",
    "        for token in sent:\n",
    "            trainFile.write(token['orth'] + ' ' + '-' + ' ' + '-' + ' ' + token['ner'] + '\\n')\n",
    "        trainFile.write('\\n')\n",
    "\n",
    "    for sent in test:\n",
    "        for token in sent:\n",
    "            testFile.write(token['orth'] + ' ' + '-' + ' ' + '-' + ' ' + token['ner'] + '\\n')\n",
    "        testFile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}